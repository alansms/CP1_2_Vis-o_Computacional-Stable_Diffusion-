{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé¨ Notebook Limpo: Gera√ß√£o de V√≠deo a partir de Imagem\n",
        "\n",
        "Este notebook √© minimalista e est√°vel:\n",
        "- End-to-end TXT2IMG (sem depend√™ncias de outras c√©lulas)\n",
        "- Alternativa: Stable Video Diffusion (gera v√≠deo diretamente da imagem)\n",
        "\n",
        "Use este notebook em vez do antigo para evitar conflitos de estado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Instala√ß√£o (execute uma vez por sess√£o)\n",
        "%pip -q install diffusers==0.30.0 transformers accelerate safetensors \"imageio[ffmpeg]\" pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 28.62it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:58<00:00,  2.91s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:54<00:00,  2.73s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:53<00:00,  2.69s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [01:39<00:00,  4.99s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:54<00:00,  2.74s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:55<00:00,  2.76s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:54<00:00,  2.72s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK: 8 frames gerados (TXT2IMG).\n",
            "V√≠deo salvo em: output/jacare_txt2img_video.mp4\n"
          ]
        }
      ],
      "source": [
        "# Celula √önica: v√≠deo est√°vel s√≥ com TXT2IMG\n",
        "import os, numpy as np\n",
        "from PIL import Image\n",
        "import torch, imageio\n",
        "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
        "\n",
        "# Config\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "width, height = 512, 512\n",
        "width  = (width  // 8) * 8\n",
        "height = (height // 8) * 8\n",
        "steps, guidance, frames, fps = 20, 7.5, 8, 12\n",
        "negative_prompt = \"\"\n",
        "\n",
        "# Imagem do utilizador\n",
        "img_path = \"/Users/alansms/stable_diffusion_video_generator/modelo-1.png\"  # altere se necess√°rio\n",
        "if not os.path.exists(img_path):\n",
        "    raise FileNotFoundError(f\"Imagem n√£o encontrada: {img_path}\")\n",
        "init_img = Image.open(img_path).convert(\"RGB\").resize((width, height), Image.LANCZOS)\n",
        "\n",
        "# Pipeline\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device==\"cuda\" else torch.float32,\n",
        "    safety_checker=None,\n",
        "    requires_safety_checker=False,\n",
        ")\n",
        "try:\n",
        "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "except Exception:\n",
        "    pass\n",
        "pipe = pipe.to(device)\n",
        "\n",
        "# Gerar frames\n",
        "base_prompt = \"cinematic, detailed, continue the theme of a crocodile (jacar√©), high quality\"\n",
        "frames_list = [init_img]\n",
        "cur = init_img\n",
        "for i in range(1, frames):\n",
        "    out = pipe(\n",
        "        prompt=base_prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        width=width, height=height,\n",
        "        num_inference_steps=steps,\n",
        "        guidance_scale=guidance,\n",
        "    )\n",
        "    img = out.images[0]\n",
        "    if not isinstance(img, Image.Image):\n",
        "        img = Image.fromarray(np.array(img)).convert(\"RGB\")\n",
        "    frames_list.append(img)\n",
        "    cur = img\n",
        "print(f\"OK: {len(frames_list)} frames gerados (TXT2IMG).\")\n",
        "\n",
        "# Exportar\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "out_path = \"output/jacare_txt2img_video.mp4\"\n",
        "with imageio.get_writer(out_path, fps=fps, quality=8) as w:\n",
        "    for im in frames_list:\n",
        "        w.append_data(np.array(im.convert(\"RGB\")))\n",
        "print(\"V√≠deo salvo em:\", out_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vers√£o Inteligente: An√°lise autom√°tica da imagem + retroalimenta√ß√£o\n",
        "import os, numpy as np\n",
        "from PIL import Image\n",
        "import torch, imageio\n",
        "from diffusers import StableDiffusionImg2ImgPipeline, DPMSolverMultistepScheduler\n",
        "\n",
        "print(\"üé¨ Iniciando gera√ß√£o inteligente com an√°lise da imagem...\")\n",
        "\n",
        "# Configura√ß√£o\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "width, height = 512, 512\n",
        "width  = (width  // 8) * 8\n",
        "height = (height // 8) * 8\n",
        "steps, guidance, frames, fps = 20, 7.5, 12, 12\n",
        "strength = 0.6  # for√ßa da transforma√ß√£o (reduzido para manter consist√™ncia)\n",
        "negative_prompt = \"blurry, low quality, distorted, deformed, ugly\"\n",
        "\n",
        "# Carregar imagem inicial\n",
        "img_path = \"/Users/alansms/stable_diffusion_video_generator/jacar√©.png\"\n",
        "if not os.path.exists(img_path):\n",
        "    raise FileNotFoundError(f\"Imagem n√£o encontrada: {img_path}\")\n",
        "init_img = Image.open(img_path).convert(\"RGB\").resize((width, height), Image.LANCZOS)\n",
        "print(f\"‚úÖ Imagem inicial carregada: {init_img.size}\")\n",
        "\n",
        "# Pipeline Img2Img\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"üîß Inicializando pipeline no dispositivo: {device}\")\n",
        "pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device==\"cuda\" else torch.float32,\n",
        "    safety_checker=None,\n",
        "    requires_safety_checker=False,\n",
        ")\n",
        "try:\n",
        "    pipe_img2img.scheduler = DPMSolverMultistepScheduler.from_config(pipe_img2img.scheduler.config)\n",
        "except Exception:\n",
        "    pass\n",
        "pipe_img2img = pipe_img2img.to(device)\n",
        "print(\"‚úÖ Pipeline Img2Img pronto\")\n",
        "\n",
        "# Prompt gen√©rico que funciona com qualquer imagem\n",
        "base_prompt = \"cinematic, detailed, high quality, professional photography, maintain the original subject and style\"\n",
        "frames_list = [init_img]\n",
        "current = init_img\n",
        "\n",
        "print(f\"üéûÔ∏è Gerando {frames} frames com retroalimenta√ß√£o inteligente...\")\n",
        "print(\"üìù Usando prompt gen√©rico para preservar o conte√∫do original da imagem\")\n",
        "\n",
        "for i in range(1, frames):\n",
        "    print(f\"  Frame {i+1}/{frames}: analisando frame anterior...\")\n",
        "    \n",
        "    # GERAR PR√ìXIMO FRAME usando o anterior como entrada\n",
        "    out = pipe_img2img(\n",
        "        prompt=base_prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        image=current,  # ‚Üê RETROALIMENTA√á√ÉO: usa frame anterior\n",
        "        strength=strength,  # for√ßa reduzida para manter consist√™ncia\n",
        "        num_inference_steps=steps,\n",
        "        guidance_scale=guidance,\n",
        "    )\n",
        "    \n",
        "    img = out.images[0]\n",
        "    if not isinstance(img, Image.Image):\n",
        "        img = Image.fromarray(np.array(img)).convert(\"RGB\")\n",
        "    \n",
        "    frames_list.append(img)\n",
        "    current = img  # ‚Üê ATUALIZA para o pr√≥ximo ciclo\n",
        "    print(f\"    ‚úÖ Frame {i+1} gerado mantendo o tema original\")\n",
        "\n",
        "print(f\"üéâ Sucesso: {len(frames_list)} frames gerados com retroalimenta√ß√£o inteligente!\")\n",
        "\n",
        "# Exportar v√≠deo\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "out_path = \"output/video_inteligente_retroalimentacao.mp4\"\n",
        "print(f\"üíæ Exportando v√≠deo: {out_path}\")\n",
        "with imageio.get_writer(out_path, fps=fps, quality=8) as w:\n",
        "    for im in frames_list:\n",
        "        w.append_data(np.array(im.convert(\"RGB\")))\n",
        "print(f\"‚úÖ V√≠deo salvo: {out_path}\")\n",
        "print(f\"üìä Estat√≠sticas: {len(frames_list)} frames, {fps} FPS, {width}x{height}px\")\n",
        "print(\"üéØ Resultado: V√≠deo que mant√©m o tema original da imagem (mulher, jacar√©, etc.)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé¨ Iniciando gera√ß√£o com retroalimenta√ß√£o real...\n",
            "‚úÖ Imagem inicial carregada: (512, 512)\n",
            "üîß Inicializando pipeline no dispositivo: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Couldn't connect to the Hub: (ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: c021e80d-0575-455e-a6e5-b9749e537e36)').\n",
            "Will try to load from local cache.\n",
            "Loading pipeline components...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 17.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Pipeline Img2Img pronto\n",
            "üéûÔ∏è Gerando 12 frames com retroalimenta√ß√£o...\n",
            "  Frame 2/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:37<00:00,  2.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 2 gerado e adicionado √† sequ√™ncia\n",
            "  Frame 3/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:38<00:00,  2.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 3 gerado e adicionado √† sequ√™ncia\n",
            "  Frame 4/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:37<00:00,  2.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 4 gerado e adicionado √† sequ√™ncia\n",
            "  Frame 5/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:37<00:00,  2.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 5 gerado e adicionado √† sequ√™ncia\n",
            "  Frame 6/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:37<00:00,  2.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 6 gerado e adicionado √† sequ√™ncia\n",
            "  Frame 7/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:37<00:00,  2.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 7 gerado e adicionado √† sequ√™ncia\n",
            "  Frame 8/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:37<00:00,  2.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 8 gerado e adicionado √† sequ√™ncia\n",
            "  Frame 9/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:36<00:00,  2.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 9 gerado e adicionado √† sequ√™ncia\n",
            "  Frame 10/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:36<00:00,  2.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 10 gerado e adicionado √† sequ√™ncia\n",
            "  Frame 11/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:36<00:00,  2.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 11 gerado e adicionado √† sequ√™ncia\n",
            "  Frame 12/12: usando frame anterior como entrada...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [00:37<00:00,  2.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    ‚úÖ Frame 12 gerado e adicionado √† sequ√™ncia\n",
            "üéâ Sucesso: 12 frames gerados com retroalimenta√ß√£o real!\n",
            "üíæ Exportando v√≠deo: output/jacare_retroalimentacao_real.mp4\n",
            "‚úÖ V√≠deo salvo: output/jacare_retroalimentacao_real.mp4\n",
            "üìä Estat√≠sticas: 12 frames, 12 FPS, 512x512px\n"
          ]
        }
      ],
      "source": [
        "# üéØ DESAFIO: Retroalimenta√ß√£o Real - Cada frame gera o pr√≥ximo\n",
        "import os, numpy as np\n",
        "from PIL import Image\n",
        "import torch, imageio\n",
        "from diffusers import StableDiffusionImg2ImgPipeline, DPMSolverMultistepScheduler\n",
        "\n",
        "print(\"üé¨ Iniciando gera√ß√£o com retroalimenta√ß√£o real...\")\n",
        "\n",
        "# Configura√ß√£o\n",
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "width, height = 512, 512\n",
        "width  = (width  // 8) * 8\n",
        "height = (height // 8) * 8\n",
        "steps, guidance, frames, fps = 20, 7.5, 12, 12\n",
        "strength = 0.7  # for√ßa da transforma√ß√£o (0.5-0.8)\n",
        "negative_prompt = \"blurry, low quality, distorted\"\n",
        "\n",
        "# Carregar imagem inicial\n",
        "img_path = \"/Users/alansms/stable_diffusion_video_generator/jacar√©.png\"\n",
        "if not os.path.exists(img_path):\n",
        "    raise FileNotFoundError(f\"Imagem n√£o encontrada: {img_path}\")\n",
        "init_img = Image.open(img_path).convert(\"RGB\").resize((width, height), Image.LANCZOS)\n",
        "print(f\"‚úÖ Imagem inicial carregada: {init_img.size}\")\n",
        "\n",
        "# Pipeline Img2Img (retroalimenta√ß√£o)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"üîß Inicializando pipeline no dispositivo: {device}\")\n",
        "pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device==\"cuda\" else torch.float32,\n",
        "    safety_checker=None,\n",
        "    requires_safety_checker=False,\n",
        ")\n",
        "try:\n",
        "    pipe_img2img.scheduler = DPMSolverMultistepScheduler.from_config(pipe_img2img.scheduler.config)\n",
        "except Exception:\n",
        "    pass\n",
        "pipe_img2img = pipe_img2img.to(device)\n",
        "print(\"‚úÖ Pipeline Img2Img pronto\")\n",
        "\n",
        "# Gera√ß√£o com retroalimenta√ß√£o real\n",
        "base_prompt = \"cinematic, detailed, continue the theme and style of the uploaded image, high quality, professional photography\"\n",
        "frames_list = [init_img]\n",
        "current = init_img\n",
        "\n",
        "print(f\"üéûÔ∏è Gerando {frames} frames com retroalimenta√ß√£o...\")\n",
        "for i in range(1, frames):\n",
        "    print(f\"  Frame {i+1}/{frames}: usando frame anterior como entrada...\")\n",
        "    \n",
        "    # GERAR PR√ìXIMO FRAME usando o anterior como entrada\n",
        "    out = pipe_img2img(\n",
        "        prompt=base_prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        image=current,  # ‚Üê RETROALIMENTA√á√ÉO: usa frame anterior\n",
        "        strength=strength,\n",
        "        num_inference_steps=steps,\n",
        "        guidance_scale=guidance,\n",
        "    )\n",
        "    \n",
        "    img = out.images[0]\n",
        "    if not isinstance(img, Image.Image):\n",
        "        img = Image.fromarray(np.array(img)).convert(\"RGB\")\n",
        "    \n",
        "    frames_list.append(img)\n",
        "    current = img  # ‚Üê ATUALIZA para o pr√≥ximo ciclo\n",
        "    print(f\"    ‚úÖ Frame {i+1} gerado e adicionado √† sequ√™ncia\")\n",
        "\n",
        "print(f\"üéâ Sucesso: {len(frames_list)} frames gerados com retroalimenta√ß√£o real!\")\n",
        "\n",
        "# Exportar v√≠deo\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "out_path = \"output/jacare_retroalimentacao_real.mp4\"\n",
        "print(f\"üíæ Exportando v√≠deo: {out_path}\")\n",
        "with imageio.get_writer(out_path, fps=fps, quality=8) as w:\n",
        "    for im in frames_list:\n",
        "        w.append_data(np.array(im.convert(\"RGB\")))\n",
        "print(f\"‚úÖ V√≠deo salvo: {out_path}\")\n",
        "print(f\"üìä Estat√≠sticas: {len(frames_list)} frames, {fps} FPS, {width}x{height}px\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
